{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8VvfXDERayF"
   },
   "source": [
    "## Intro\n",
    "Take Election tweets between AUG and OCT Look at\n",
    "\n",
    "\n",
    "*   Common words\n",
    "  * per like\n",
    "  * trump or biden\n",
    "      * sentiment analysis (textblob gives you subjectivity as well)\n",
    "* time of day?\n",
    "  * need to convert\n",
    "\n",
    "How was this scraped?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "id": "A9urHn1xRZc4",
    "outputId": "b8851d29-643d-423c-9868-1c369a5cf676"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created At</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Id</th>\n",
       "      <th>Language</th>\n",
       "      <th>Link</th>\n",
       "      <th>Name</th>\n",
       "      <th>Reply To</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>User Id</th>\n",
       "      <th>Username</th>\n",
       "      <th>F1</th>\n",
       "      <th>Likes Count</th>\n",
       "      <th>Replies Count</th>\n",
       "      <th>Retweets Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-28 19:13:51 IST</td>\n",
       "      <td>['uselection']</td>\n",
       "      <td>1321447588688584704</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/mariawirth1/status/1321447...</td>\n",
       "      <td>Maria Wirth</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>In 2016, almost all Germans were against Trump...</td>\n",
       "      <td>1358917686</td>\n",
       "      <td>mariawirth1</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-28 19:09:31 IST</td>\n",
       "      <td>['covid', 'nagornokarabakh']</td>\n",
       "      <td>1321446498794569728</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/AliTahmizian/status/132144...</td>\n",
       "      <td>Alison Meuse</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>Azerbaijan's offensive may have been timed to ...</td>\n",
       "      <td>394593711</td>\n",
       "      <td>alitahmizian</td>\n",
       "      <td>141</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-28 19:06:28 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1321445733904617472</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/rcolvile/status/1321445733...</td>\n",
       "      <td>Robert Colvile</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>US election veterans - what is the best strate...</td>\n",
       "      <td>18331985</td>\n",
       "      <td>rcolvile</td>\n",
       "      <td>157</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-28 18:47:09 IST</td>\n",
       "      <td>['uselection']</td>\n",
       "      <td>1321440873113112576</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/SkyNews/status/13214408731...</td>\n",
       "      <td>SkyNews</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>Eyewitness: Voters with doubts about both cand...</td>\n",
       "      <td>7587032</td>\n",
       "      <td>skynews</td>\n",
       "      <td>243</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-28 18:38:01 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1321438571585245184</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/VABVOX/status/132143857158...</td>\n",
       "      <td>Victoria Brownworth #AntiFascistVoter</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>Make it all blue.   Build your own US election...</td>\n",
       "      <td>138168339</td>\n",
       "      <td>vabvox</td>\n",
       "      <td>299</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>2020-10-24 00:51:08 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319720532607143936</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/talkRADIO/status/131972053...</td>\n",
       "      <td>talkRADIO</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>Following last night's presidential debate, wh...</td>\n",
       "      <td>3380282686</td>\n",
       "      <td>talkradio</td>\n",
       "      <td>20424</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>2020-10-24 00:46:06 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319719262580330496</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/thehill/status/13197192625...</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>NASA astronaut Kate Rubins votes from space in...</td>\n",
       "      <td>1917731</td>\n",
       "      <td>thehill</td>\n",
       "      <td>20435</td>\n",
       "      <td>623</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>2020-10-24 00:42:35 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319718380841144320</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/akhilkom/status/1319718380...</td>\n",
       "      <td>Akhil</td>\n",
       "      <td>{'user_id': '18690738', 'username': '_bikerchi...</td>\n",
       "      <td>@_bikerchick @dbarrett @businessinsider I live...</td>\n",
       "      <td>32863133</td>\n",
       "      <td>akhilkom</td>\n",
       "      <td>20444</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>2020-10-24 00:40:17 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319717802182348800</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/gathara/status/13197178021...</td>\n",
       "      <td>gathara</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>There's nothing normal about being forced to \"...</td>\n",
       "      <td>15659814</td>\n",
       "      <td>gathara</td>\n",
       "      <td>20455</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>2020-10-24 00:36:27 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319716834518716416</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/SorceyMz/status/1319716834...</td>\n",
       "      <td>Mz sorcey</td>\n",
       "      <td>{'user_id': '18166778', 'username': 'Jim_Jordan'}</td>\n",
       "      <td>@Jim_Jordan JUST IN: Trump announces that Nort...</td>\n",
       "      <td>367975626</td>\n",
       "      <td>sorceymz</td>\n",
       "      <td>20464</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5050 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Created At                      Hashtags  \\\n",
       "0     2020-10-28 19:13:51 IST                ['uselection']   \n",
       "1     2020-10-28 19:09:31 IST  ['covid', 'nagornokarabakh']   \n",
       "2     2020-10-28 19:06:28 IST                            []   \n",
       "3     2020-10-28 18:47:09 IST                ['uselection']   \n",
       "4     2020-10-28 18:38:01 IST                            []   \n",
       "...                       ...                           ...   \n",
       "5045  2020-10-24 00:51:08 IST                            []   \n",
       "5046  2020-10-24 00:46:06 IST                            []   \n",
       "5047  2020-10-24 00:42:35 IST                            []   \n",
       "5048  2020-10-24 00:40:17 IST                            []   \n",
       "5049  2020-10-24 00:36:27 IST                            []   \n",
       "\n",
       "                       Id Language  \\\n",
       "0     1321447588688584704       en   \n",
       "1     1321446498794569728       en   \n",
       "2     1321445733904617472       en   \n",
       "3     1321440873113112576       en   \n",
       "4     1321438571585245184       en   \n",
       "...                   ...      ...   \n",
       "5045  1319720532607143936       en   \n",
       "5046  1319719262580330496       en   \n",
       "5047  1319718380841144320       en   \n",
       "5048  1319717802182348800       en   \n",
       "5049  1319716834518716416       en   \n",
       "\n",
       "                                                   Link  \\\n",
       "0     https://twitter.com/mariawirth1/status/1321447...   \n",
       "1     https://twitter.com/AliTahmizian/status/132144...   \n",
       "2     https://twitter.com/rcolvile/status/1321445733...   \n",
       "3     https://twitter.com/SkyNews/status/13214408731...   \n",
       "4     https://twitter.com/VABVOX/status/132143857158...   \n",
       "...                                                 ...   \n",
       "5045  https://twitter.com/talkRADIO/status/131972053...   \n",
       "5046  https://twitter.com/thehill/status/13197192625...   \n",
       "5047  https://twitter.com/akhilkom/status/1319718380...   \n",
       "5048  https://twitter.com/gathara/status/13197178021...   \n",
       "5049  https://twitter.com/SorceyMz/status/1319716834...   \n",
       "\n",
       "                                       Name  \\\n",
       "0                               Maria Wirth   \n",
       "1                              Alison Meuse   \n",
       "2                            Robert Colvile   \n",
       "3                                   SkyNews   \n",
       "4     Victoria Brownworth #AntiFascistVoter   \n",
       "...                                     ...   \n",
       "5045                              talkRADIO   \n",
       "5046                               The Hill   \n",
       "5047                                  Akhil   \n",
       "5048                                gathara   \n",
       "5049                              Mz sorcey   \n",
       "\n",
       "                                               Reply To  \\\n",
       "0                   {'user_id': None, 'username': None}   \n",
       "1                   {'user_id': None, 'username': None}   \n",
       "2                   {'user_id': None, 'username': None}   \n",
       "3                   {'user_id': None, 'username': None}   \n",
       "4                   {'user_id': None, 'username': None}   \n",
       "...                                                 ...   \n",
       "5045                {'user_id': None, 'username': None}   \n",
       "5046                {'user_id': None, 'username': None}   \n",
       "5047  {'user_id': '18690738', 'username': '_bikerchi...   \n",
       "5048                {'user_id': None, 'username': None}   \n",
       "5049  {'user_id': '18166778', 'username': 'Jim_Jordan'}   \n",
       "\n",
       "                                                  Tweet     User Id  \\\n",
       "0     In 2016, almost all Germans were against Trump...  1358917686   \n",
       "1     Azerbaijan's offensive may have been timed to ...   394593711   \n",
       "2     US election veterans - what is the best strate...    18331985   \n",
       "3     Eyewitness: Voters with doubts about both cand...     7587032   \n",
       "4     Make it all blue.   Build your own US election...   138168339   \n",
       "...                                                 ...         ...   \n",
       "5045  Following last night's presidential debate, wh...  3380282686   \n",
       "5046  NASA astronaut Kate Rubins votes from space in...     1917731   \n",
       "5047  @_bikerchick @dbarrett @businessinsider I live...    32863133   \n",
       "5048  There's nothing normal about being forced to \"...    15659814   \n",
       "5049  @Jim_Jordan JUST IN: Trump announces that Nort...   367975626   \n",
       "\n",
       "          Username     F1  Likes Count  Replies Count  Retweets Count  \n",
       "0      mariawirth1    118          119              4              20  \n",
       "1     alitahmizian    141           25              3              13  \n",
       "2         rcolvile    157           20             34               1  \n",
       "3          skynews    243           20             19               3  \n",
       "4           vabvox    299           24              1               6  \n",
       "...            ...    ...          ...            ...             ...  \n",
       "5045     talkradio  20424          137             60             155  \n",
       "5046       thehill  20435          623             26              82  \n",
       "5047      akhilkom  20444           20              0               0  \n",
       "5048       gathara  20455           82              8              35  \n",
       "5049      sorceymz  20464           20              1               2  \n",
       "\n",
       "[5050 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_orig = pd.read_csv('../data/us_election-subset20like.csv')\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BidIgCQ6iLrd",
    "outputId": "2867431a-14ae-48b2-a1f9-ec9e44aa1ce3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                             4035\n",
       "['uselection']                   81\n",
       "['untrendoctober']               20\n",
       "['uselection2020']               17\n",
       "['election2020']                 14\n",
       "['covid19']                      12\n",
       "['justvote']                     12\n",
       "['vote']                         11\n",
       "['breaking']                     10\n",
       "['newsnight']                     9\n",
       "['debates2020']                   9\n",
       "['gravitas']                      8\n",
       "['uselection', 'kayburley']       7\n",
       "['uselections2020']               7\n",
       "['coronavirus']                   7\n",
       "Name: Hashtags, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig['Hashtags'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "i3gx6HEIlvwO",
    "outputId": "bce3ddab-bae7-418d-b47f-c90e6042bd2d"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nlp.Defaults.stop_words.union(['election', 'election.', '&amp;', '#uselection', \"it's\", \"election?\", \"election,\", \"|\",\n",
    "                                            \"election:\", \"biden's\", \"biden:\", \"biden.\"])\n",
    "# tokenizer pipe\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['Tweet'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in stop_words) & (token.is_punct == False) & (token.is_space is False):\n",
    "            doc_tokens.append(token.lemma_.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 926),\n",
       " ('vote', 798),\n",
       " ('biden', 472),\n",
       " ('win', 320),\n",
       " ('day', 312),\n",
       " ('say', 287),\n",
       " ('like', 260),\n",
       " ('2020', 259),\n",
       " ('people', 253),\n",
       " ('donald', 245),\n",
       " ('think', 242),\n",
       " ('go', 241),\n",
       " ('week', 239),\n",
       " ('president', 228),\n",
       " ('american', 220),\n",
       " ('time', 212),\n",
       " ('2020:', 206),\n",
       " ('joe', 204),\n",
       " ('know', 198),\n",
       " ('poll', 195),\n",
       " ('new', 194),\n",
       " ('want', 182),\n",
       " ('voter', 164),\n",
       " ('world', 162),\n",
       " ('debate', 160),\n",
       " ('twitter', 157),\n",
       " ('live', 156),\n",
       " ('facebook', 155),\n",
       " ('upcoming', 154),\n",
       " ('result', 154)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count = Counter()\n",
    "for doc in tokens:\n",
    "    word_count.update(doc)\n",
    "word_count.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what words are associated with Trump and Biden\n",
    "df_trump = df.copy()\n",
    "df_trump = df_trump[df_trump['Tweet'].str.contains('Trump')]\n",
    "tokens = []\n",
    "for doc in tokenizer.pipe(df_trump['Tweet'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in stop_words) & (token.is_punct == False) & (token.is_space is False):\n",
    "            doc_tokens.append(token.lemma_.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df_trump['trump_tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 894),\n",
       " ('biden', 298),\n",
       " ('donald', 241),\n",
       " ('win', 162),\n",
       " ('vote', 156),\n",
       " ('president', 151),\n",
       " ('2020:', 110),\n",
       " ('joe', 109),\n",
       " ('say', 103),\n",
       " (\"trump's\", 89),\n",
       " ('@realdonaldtrump', 87),\n",
       " ('debate', 87),\n",
       " ('poll', 71),\n",
       " ('day', 68),\n",
       " ('campaign', 66),\n",
       " ('presidential', 65),\n",
       " ('think', 55),\n",
       " ('trumpâ€™s', 55),\n",
       " ('go', 54),\n",
       " ('voter', 53),\n",
       " ('live', 52),\n",
       " ('like', 51),\n",
       " ('people', 50),\n",
       " ('lose', 50),\n",
       " ('want', 50),\n",
       " ('2020', 47),\n",
       " ('#trump', 46),\n",
       " ('trump.', 45),\n",
       " ('american', 45),\n",
       " ('week', 45)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_count = Counter()\n",
    "for doc in tokens:\n",
    "    trump_count.update(doc)\n",
    "trump_count.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for Biden\n",
    "df_biden = df.copy()\n",
    "df_biden = df_biden[df_biden['Tweet'].str.contains('Biden')]\n",
    "tokens = []\n",
    "for doc in tokenizer.pipe(df_biden['Tweet'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in stop_words) & (token.is_punct is False) & (token.is_space is False):\n",
    "            doc_tokens.append(token.lemma_.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df_biden['biden_tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('biden', 453),\n",
       " ('trump', 303),\n",
       " ('joe', 193),\n",
       " ('vote', 119),\n",
       " ('win', 110),\n",
       " ('donald', 78),\n",
       " ('debate', 68),\n",
       " ('2020:', 63),\n",
       " ('president', 60),\n",
       " ('poll', 58),\n",
       " ('presidential', 50),\n",
       " ('say', 48),\n",
       " ('@joebiden', 42),\n",
       " ('campaign', 41),\n",
       " ('day', 37),\n",
       " ('live', 33),\n",
       " ('know', 30),\n",
       " ('science', 30),\n",
       " ('#trump', 28),\n",
       " ('2020', 28),\n",
       " ('@realdonaldtrump', 28),\n",
       " ('people', 27),\n",
       " ('ðŸ‡ºðŸ‡¸', 27),\n",
       " ('state', 27),\n",
       " ('democratic', 26),\n",
       " ('like', 26),\n",
       " ('new', 26),\n",
       " ('trump:', 26),\n",
       " ('want', 26),\n",
       " ('covid', 24)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_count = Counter()\n",
    "for doc in tokens:\n",
    "    biden_count.update(doc)\n",
    "biden_count.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 121),\n",
       " ('vote', 102),\n",
       " ('biden', 66),\n",
       " ('people', 38),\n",
       " ('say', 37),\n",
       " ('president', 37),\n",
       " ('joe', 33),\n",
       " ('like', 33),\n",
       " ('russian', 31),\n",
       " ('win', 30),\n",
       " ('day', 30),\n",
       " ('week', 29),\n",
       " ('foreign', 28),\n",
       " ('think', 26),\n",
       " ('twitter', 25),\n",
       " ('donald', 23),\n",
       " ('tell', 23),\n",
       " ('go', 22),\n",
       " ('new', 22),\n",
       " ('year', 22),\n",
       " ('want', 22),\n",
       " ('time', 21),\n",
       " ('american', 21),\n",
       " ('campaign', 20),\n",
       " ('help', 20),\n",
       " ('voter', 20),\n",
       " ('result', 20),\n",
       " ('world', 19),\n",
       " ('2020', 19),\n",
       " ('influence', 19)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How about words with the top 10% of likes (from those above 20 likes)\n",
    "df_top = df.copy()\n",
    "df_top = df_top[df_top['Likes Count'] > df_top['Likes Count'].quantile(0.9)]\n",
    "tokens = []\n",
    "for doc in tokenizer.pipe(df_top['Tweet'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in stop_words) & (token.is_punct is False) & (token.is_space is False):\n",
    "            doc_tokens.append(token.lemma_.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df_top['like_tokens'] = tokens\n",
    "\n",
    "top_count = Counter()\n",
    "for doc in tokens:\n",
    "    top_count.update(doc)\n",
    "top_count.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "subj = lambda x: TextBlob(x).subjectivity\n",
    "senta = lambda x: TextBlob(x).polarity\n",
    "\n",
    "df['Subjectivity'] = df['Tweet'].apply(subj)\n",
    "df['Sentiment'] = df['Tweet'].apply(senta)\n",
    "\n",
    "df_trump['Subjectivity'] = df_trump['Tweet'].apply(subj)\n",
    "df_trump['Sentiment'] = df_trump['Tweet'].apply(senta)\n",
    "\n",
    "df_biden['Subjectivity'] = df_biden['Tweet'].apply(subj)\n",
    "df_biden['Sentiment'] = df_biden['Tweet'].apply(senta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, 0.0835517950935405\n",
      "Trump, 0.09077470197483492\n",
      "Biden, 0.10920995477507763\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall,\", df['Sentiment'].mean())\n",
    "print(\"Trump,\", df_trump['Sentiment'].mean())\n",
    "print(\"Biden, \", df_biden['Sentiment'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall 0.3652150355861506\n",
      "Trump 0.38315128055326403\n",
      "Biden 0.39690158037524315\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall\", df['Subjectivity'].mean())\n",
    "print(\"Trump\", df_trump['Subjectivity'].mean())\n",
    "print(\"Biden\", df_biden['Subjectivity'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          (0.1259259259259259, 0.2851851851851852)\n",
       "1                                        (0.0, 0.0)\n",
       "2        (0.26666666666666666, 0.39999999999999997)\n",
       "3                                        (0.5, 0.5)\n",
       "4                         (0.4666666666666666, 0.5)\n",
       "                           ...                     \n",
       "5045     (0.26666666666666666, 0.18888888888888888)\n",
       "5046                                     (0.0, 0.0)\n",
       "5047     (0.11212121212121212, 0.30833333333333335)\n",
       "5048    (-0.03750000000000001, 0.46249999999999997)\n",
       "5049    (-0.09722222222222221, 0.10555555555555556)\n",
       "Name: Tweet, Length: 5050, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now think do you want to scatter just the mean or do you want to try and scatter all the scores?\n",
    "df['Tweet'].apply(lambda x: TextBlob(x).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.083552</td>\n",
       "      <td>0.365215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>0.090775</td>\n",
       "      <td>0.383151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biden</th>\n",
       "      <td>0.109210</td>\n",
       "      <td>0.396902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment  Subjectivity\n",
       "Overall   0.083552      0.365215\n",
       "Trump     0.090775      0.383151\n",
       "Biden     0.109210      0.396902"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scatter = pd.DataFrame(data=[[0.0835517950935405, 0.3652150355861506], [0.09077470197483492, 0.38315128055326403], [0.10920995477507763, 0.39690158037524315]],\n",
    "                         index=[\"Overall\", \"Trump\", \"Biden\"], columns=['Sentiment', 'Subjectivity'])\n",
    "df_scatter#.plot.scatter(x=df_scatter.Sentiment, y=df_scatter.Subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textgenrnn\n",
      "  Downloading textgenrnn-2.0.0.tar.gz (1.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from textgenrnn) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from textgenrnn) (0.23.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from textgenrnn) (4.36.1)\n",
      "Requirement already satisfied, skipping upgrade: keras in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from textgenrnn) (2.3.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow>=2.1.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from textgenrnn) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from h5py->textgenrnn) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from h5py->textgenrnn) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from scikit-learn->textgenrnn) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from scikit-learn->textgenrnn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from scikit-learn->textgenrnn) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from keras->textgenrnn) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from keras->textgenrnn) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from keras->textgenrnn) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (3.12.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (2.2.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (0.33.6)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (1.29.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorflow>=2.1.0->textgenrnn) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from protobuf>=3.8.0->tensorflow>=2.1.0->textgenrnn) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (1.6.0.post3)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (3.2.2)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (4.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in c:\\users\\jonma\\programming\\anaconda\\lib\\site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->textgenrnn) (7.2.0)\n",
      "Building wheels for collected packages: textgenrnn\n",
      "  Building wheel for textgenrnn (setup.py): started\n",
      "  Building wheel for textgenrnn (setup.py): finished with status 'done'\n",
      "  Created wheel for textgenrnn: filename=textgenrnn-2.0.0-py3-none-any.whl size=1733683 sha256=5f9f8f23e7ba00df9a61f9e90a44c9b6c05cc9a60d69d6db5adceb7df71b0ee4\n",
      "  Stored in directory: c:\\users\\jonma\\appdata\\local\\pip\\cache\\wheels\\8a\\df\\6c\\327949b0ebdf6eac64ead76d9a15cfd392565aa8321e5877c4\n",
      "Successfully built textgenrnn\n",
      "Installing collected packages: textgenrnn, requests\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.20.1\n",
      "    Uninstalling requests-2.20.1:\n",
      "      Successfully uninstalled requests-2.20.1\n",
      "Successfully installed requests-2.24.0 textgenrnn-2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "awsebcli 3.18.1 requires requests<2.21,>=2.20.1, but you'll have requests 2.24.0 which is incompatible.\n",
      "WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jonma\\programming\\anaconda\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Now let's look at some text generation!\n",
    "!pip3 install -U textgenrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "US-Election-Tweets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "NLP-4-1 (Python 3)",
   "language": "python",
   "name": "nlp-4-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

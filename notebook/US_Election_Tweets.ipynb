{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8VvfXDERayF"
   },
   "source": [
    "## NLP exercise using Tableau\n",
    "\n",
    "Take U.S. Election tweets between AUG and OCT Look at\n",
    "\n",
    "*   Common words\n",
    "  * for high number of likes\n",
    "  * trump or biden\n",
    "      * sentiment analysis (textblob gives you subjectivity as well)\n",
    "* LDA topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 966
    },
    "id": "A9urHn1xRZc4",
    "outputId": "b8851d29-643d-423c-9868-1c369a5cf676"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Created At</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Id</th>\n",
       "      <th>Language</th>\n",
       "      <th>Link</th>\n",
       "      <th>Name</th>\n",
       "      <th>Reply To</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>User Id</th>\n",
       "      <th>Username</th>\n",
       "      <th>F1</th>\n",
       "      <th>Likes Count</th>\n",
       "      <th>Replies Count</th>\n",
       "      <th>Retweets Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-28 19:13:51 IST</td>\n",
       "      <td>['uselection']</td>\n",
       "      <td>1321447588688584704</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/mariawirth1/status/1321447...</td>\n",
       "      <td>Maria Wirth</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>In 2016, almost all Germans were against Trump...</td>\n",
       "      <td>1358917686</td>\n",
       "      <td>mariawirth1</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-28 19:09:31 IST</td>\n",
       "      <td>['covid', 'nagornokarabakh']</td>\n",
       "      <td>1321446498794569728</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/AliTahmizian/status/132144...</td>\n",
       "      <td>Alison Meuse</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>Azerbaijan's offensive may have been timed to ...</td>\n",
       "      <td>394593711</td>\n",
       "      <td>alitahmizian</td>\n",
       "      <td>141</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-28 19:06:28 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1321445733904617472</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/rcolvile/status/1321445733...</td>\n",
       "      <td>Robert Colvile</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>US election veterans - what is the best strate...</td>\n",
       "      <td>18331985</td>\n",
       "      <td>rcolvile</td>\n",
       "      <td>157</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-28 18:47:09 IST</td>\n",
       "      <td>['uselection']</td>\n",
       "      <td>1321440873113112576</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/SkyNews/status/13214408731...</td>\n",
       "      <td>SkyNews</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>Eyewitness: Voters with doubts about both cand...</td>\n",
       "      <td>7587032</td>\n",
       "      <td>skynews</td>\n",
       "      <td>243</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-28 18:38:01 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1321438571585245184</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/VABVOX/status/132143857158...</td>\n",
       "      <td>Victoria Brownworth #AntiFascistVoter</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>Make it all blue.   Build your own US election...</td>\n",
       "      <td>138168339</td>\n",
       "      <td>vabvox</td>\n",
       "      <td>299</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>2020-10-24 00:51:08 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319720532607143936</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/talkRADIO/status/131972053...</td>\n",
       "      <td>talkRADIO</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>Following last night's presidential debate, wh...</td>\n",
       "      <td>3380282686</td>\n",
       "      <td>talkradio</td>\n",
       "      <td>20424</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>2020-10-24 00:46:06 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319719262580330496</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/thehill/status/13197192625...</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>NASA astronaut Kate Rubins votes from space in...</td>\n",
       "      <td>1917731</td>\n",
       "      <td>thehill</td>\n",
       "      <td>20435</td>\n",
       "      <td>623</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>2020-10-24 00:42:35 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319718380841144320</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/akhilkom/status/1319718380...</td>\n",
       "      <td>Akhil</td>\n",
       "      <td>{'user_id': '18690738', 'username': '_bikerchi...</td>\n",
       "      <td>@_bikerchick @dbarrett @businessinsider I live...</td>\n",
       "      <td>32863133</td>\n",
       "      <td>akhilkom</td>\n",
       "      <td>20444</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>2020-10-24 00:40:17 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319717802182348800</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/gathara/status/13197178021...</td>\n",
       "      <td>gathara</td>\n",
       "      <td>{'user_id': None, 'username': None}</td>\n",
       "      <td>There's nothing normal about being forced to \"...</td>\n",
       "      <td>15659814</td>\n",
       "      <td>gathara</td>\n",
       "      <td>20455</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>2020-10-24 00:36:27 IST</td>\n",
       "      <td>[]</td>\n",
       "      <td>1319716834518716416</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/SorceyMz/status/1319716834...</td>\n",
       "      <td>Mz sorcey</td>\n",
       "      <td>{'user_id': '18166778', 'username': 'Jim_Jordan'}</td>\n",
       "      <td>@Jim_Jordan JUST IN: Trump announces that Nort...</td>\n",
       "      <td>367975626</td>\n",
       "      <td>sorceymz</td>\n",
       "      <td>20464</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5050 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Created At                      Hashtags  \\\n",
       "0     2020-10-28 19:13:51 IST                ['uselection']   \n",
       "1     2020-10-28 19:09:31 IST  ['covid', 'nagornokarabakh']   \n",
       "2     2020-10-28 19:06:28 IST                            []   \n",
       "3     2020-10-28 18:47:09 IST                ['uselection']   \n",
       "4     2020-10-28 18:38:01 IST                            []   \n",
       "...                       ...                           ...   \n",
       "5045  2020-10-24 00:51:08 IST                            []   \n",
       "5046  2020-10-24 00:46:06 IST                            []   \n",
       "5047  2020-10-24 00:42:35 IST                            []   \n",
       "5048  2020-10-24 00:40:17 IST                            []   \n",
       "5049  2020-10-24 00:36:27 IST                            []   \n",
       "\n",
       "                       Id Language  \\\n",
       "0     1321447588688584704       en   \n",
       "1     1321446498794569728       en   \n",
       "2     1321445733904617472       en   \n",
       "3     1321440873113112576       en   \n",
       "4     1321438571585245184       en   \n",
       "...                   ...      ...   \n",
       "5045  1319720532607143936       en   \n",
       "5046  1319719262580330496       en   \n",
       "5047  1319718380841144320       en   \n",
       "5048  1319717802182348800       en   \n",
       "5049  1319716834518716416       en   \n",
       "\n",
       "                                                   Link  \\\n",
       "0     https://twitter.com/mariawirth1/status/1321447...   \n",
       "1     https://twitter.com/AliTahmizian/status/132144...   \n",
       "2     https://twitter.com/rcolvile/status/1321445733...   \n",
       "3     https://twitter.com/SkyNews/status/13214408731...   \n",
       "4     https://twitter.com/VABVOX/status/132143857158...   \n",
       "...                                                 ...   \n",
       "5045  https://twitter.com/talkRADIO/status/131972053...   \n",
       "5046  https://twitter.com/thehill/status/13197192625...   \n",
       "5047  https://twitter.com/akhilkom/status/1319718380...   \n",
       "5048  https://twitter.com/gathara/status/13197178021...   \n",
       "5049  https://twitter.com/SorceyMz/status/1319716834...   \n",
       "\n",
       "                                       Name  \\\n",
       "0                               Maria Wirth   \n",
       "1                              Alison Meuse   \n",
       "2                            Robert Colvile   \n",
       "3                                   SkyNews   \n",
       "4     Victoria Brownworth #AntiFascistVoter   \n",
       "...                                     ...   \n",
       "5045                              talkRADIO   \n",
       "5046                               The Hill   \n",
       "5047                                  Akhil   \n",
       "5048                                gathara   \n",
       "5049                              Mz sorcey   \n",
       "\n",
       "                                               Reply To  \\\n",
       "0                   {'user_id': None, 'username': None}   \n",
       "1                   {'user_id': None, 'username': None}   \n",
       "2                   {'user_id': None, 'username': None}   \n",
       "3                   {'user_id': None, 'username': None}   \n",
       "4                   {'user_id': None, 'username': None}   \n",
       "...                                                 ...   \n",
       "5045                {'user_id': None, 'username': None}   \n",
       "5046                {'user_id': None, 'username': None}   \n",
       "5047  {'user_id': '18690738', 'username': '_bikerchi...   \n",
       "5048                {'user_id': None, 'username': None}   \n",
       "5049  {'user_id': '18166778', 'username': 'Jim_Jordan'}   \n",
       "\n",
       "                                                  Tweet     User Id  \\\n",
       "0     In 2016, almost all Germans were against Trump...  1358917686   \n",
       "1     Azerbaijan's offensive may have been timed to ...   394593711   \n",
       "2     US election veterans - what is the best strate...    18331985   \n",
       "3     Eyewitness: Voters with doubts about both cand...     7587032   \n",
       "4     Make it all blue.   Build your own US election...   138168339   \n",
       "...                                                 ...         ...   \n",
       "5045  Following last night's presidential debate, wh...  3380282686   \n",
       "5046  NASA astronaut Kate Rubins votes from space in...     1917731   \n",
       "5047  @_bikerchick @dbarrett @businessinsider I live...    32863133   \n",
       "5048  There's nothing normal about being forced to \"...    15659814   \n",
       "5049  @Jim_Jordan JUST IN: Trump announces that Nort...   367975626   \n",
       "\n",
       "          Username     F1  Likes Count  Replies Count  Retweets Count  \n",
       "0      mariawirth1    118          119              4              20  \n",
       "1     alitahmizian    141           25              3              13  \n",
       "2         rcolvile    157           20             34               1  \n",
       "3          skynews    243           20             19               3  \n",
       "4           vabvox    299           24              1               6  \n",
       "...            ...    ...          ...            ...             ...  \n",
       "5045     talkradio  20424          137             60             155  \n",
       "5046       thehill  20435          623             26              82  \n",
       "5047      akhilkom  20444           20              0               0  \n",
       "5048       gathara  20455           82              8              35  \n",
       "5049      sorceymz  20464           20              1               2  \n",
       "\n",
       "[5050 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_orig = pd.read_csv('../data/us_election-subset20like.csv')\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BidIgCQ6iLrd",
    "outputId": "2867431a-14ae-48b2-a1f9-ec9e44aa1ce3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                             4035\n",
       "['uselection']                   81\n",
       "['untrendoctober']               20\n",
       "['uselection2020']               17\n",
       "['election2020']                 14\n",
       "['covid19']                      12\n",
       "['justvote']                     12\n",
       "['vote']                         11\n",
       "['breaking']                     10\n",
       "['newsnight']                     9\n",
       "['debates2020']                   9\n",
       "['gravitas']                      8\n",
       "['uselection', 'kayburley']       7\n",
       "['uselections2020']               7\n",
       "['coronavirus']                   7\n",
       "Name: Hashtags, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig['Hashtags'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "i3gx6HEIlvwO",
    "outputId": "bce3ddab-bae7-418d-b47f-c90e6042bd2d"
   },
   "outputs": [],
   "source": [
    "# Use spacy's tokenizer to preproccess the data\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_orig.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nlp.Defaults.stop_words.union(['election', 'election.', '&amp;', '#uselection', \"it's\", \"election?\", \"election,\", \"|\",\n",
    "                                            \"election:\", \"biden's\", \"biden:\", \"biden.\"])\n",
    "# tokenizer pipe\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['Tweet'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in stop_words) & (token.is_punct == False) & (token.is_space is False):\n",
    "            doc_tokens.append(token.lemma_.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 926),\n",
       " ('vote', 798),\n",
       " ('biden', 472),\n",
       " ('win', 320),\n",
       " ('day', 312),\n",
       " ('say', 287),\n",
       " ('like', 260),\n",
       " ('2020', 259),\n",
       " ('people', 253),\n",
       " ('donald', 245),\n",
       " ('think', 242),\n",
       " ('go', 241),\n",
       " ('week', 239),\n",
       " ('president', 228),\n",
       " ('american', 220),\n",
       " ('time', 212),\n",
       " ('2020:', 206),\n",
       " ('joe', 204),\n",
       " ('know', 198),\n",
       " ('poll', 195),\n",
       " ('new', 194),\n",
       " ('want', 182),\n",
       " ('voter', 164),\n",
       " ('world', 162),\n",
       " ('debate', 160),\n",
       " ('twitter', 157),\n",
       " ('live', 156),\n",
       " ('facebook', 155),\n",
       " ('upcoming', 154),\n",
       " ('result', 154)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count = Counter()\n",
    "for doc in tokens:\n",
    "    word_count.update(doc)\n",
    "word_count.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets that mention Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what words are associated with Trump and Biden\n",
    "df_trump = df.copy()\n",
    "df_trump = df_trump[df_trump['Tweet'].str.contains('Trump')]\n",
    "tokens = []\n",
    "for doc in tokenizer.pipe(df_trump['Tweet'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in stop_words) & (token.is_punct == False) & (token.is_space is False):\n",
    "            doc_tokens.append(token.lemma_.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df_trump['trump_tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 894),\n",
       " ('biden', 298),\n",
       " ('donald', 241),\n",
       " ('win', 162),\n",
       " ('vote', 156),\n",
       " ('president', 151),\n",
       " ('2020:', 110),\n",
       " ('joe', 109),\n",
       " ('say', 103),\n",
       " (\"trump's\", 89),\n",
       " ('@realdonaldtrump', 87),\n",
       " ('debate', 87),\n",
       " ('poll', 71),\n",
       " ('day', 68),\n",
       " ('campaign', 66),\n",
       " ('presidential', 65),\n",
       " ('think', 55),\n",
       " ('trumpâ€™s', 55),\n",
       " ('go', 54),\n",
       " ('voter', 53),\n",
       " ('live', 52),\n",
       " ('like', 51),\n",
       " ('people', 50),\n",
       " ('lose', 50),\n",
       " ('want', 50),\n",
       " ('2020', 47),\n",
       " ('#trump', 46),\n",
       " ('trump.', 45),\n",
       " ('american', 45),\n",
       " ('week', 45)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_count = Counter()\n",
    "for doc in tokens:\n",
    "    trump_count.update(doc)\n",
    "trump_count.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets that mention Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for Biden\n",
    "df_biden = df.copy()\n",
    "df_biden = df_biden[df_biden['Tweet'].str.contains('Biden')]\n",
    "tokens = []\n",
    "for doc in tokenizer.pipe(df_biden['Tweet'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in stop_words) & (token.is_punct is False) & (token.is_space is False):\n",
    "            doc_tokens.append(token.lemma_.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df_biden['biden_tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('biden', 453),\n",
       " ('trump', 303),\n",
       " ('joe', 193),\n",
       " ('vote', 119),\n",
       " ('win', 110),\n",
       " ('donald', 78),\n",
       " ('debate', 68),\n",
       " ('2020:', 63),\n",
       " ('president', 60),\n",
       " ('poll', 58),\n",
       " ('presidential', 50),\n",
       " ('say', 48),\n",
       " ('@joebiden', 42),\n",
       " ('campaign', 41),\n",
       " ('day', 37),\n",
       " ('live', 33),\n",
       " ('know', 30),\n",
       " ('science', 30),\n",
       " ('#trump', 28),\n",
       " ('2020', 28),\n",
       " ('@realdonaldtrump', 28),\n",
       " ('people', 27),\n",
       " ('ðŸ‡ºðŸ‡¸', 27),\n",
       " ('state', 27),\n",
       " ('democratic', 26),\n",
       " ('like', 26),\n",
       " ('new', 26),\n",
       " ('trump:', 26),\n",
       " ('want', 26),\n",
       " ('covid', 24)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_count = Counter()\n",
    "for doc in tokens:\n",
    "    biden_count.update(doc)\n",
    "biden_count.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 121),\n",
       " ('vote', 102),\n",
       " ('biden', 66),\n",
       " ('people', 38),\n",
       " ('say', 37),\n",
       " ('president', 37),\n",
       " ('joe', 33),\n",
       " ('like', 33),\n",
       " ('russian', 31),\n",
       " ('win', 30),\n",
       " ('day', 30),\n",
       " ('week', 29),\n",
       " ('foreign', 28),\n",
       " ('think', 26),\n",
       " ('twitter', 25),\n",
       " ('donald', 23),\n",
       " ('tell', 23),\n",
       " ('go', 22),\n",
       " ('new', 22),\n",
       " ('year', 22),\n",
       " ('want', 22),\n",
       " ('time', 21),\n",
       " ('american', 21),\n",
       " ('campaign', 20),\n",
       " ('help', 20),\n",
       " ('voter', 20),\n",
       " ('result', 20),\n",
       " ('world', 19),\n",
       " ('2020', 19),\n",
       " ('influence', 19)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How about words with the top 10% of likes (from those above 20 likes)\n",
    "df_top = df.copy()\n",
    "df_top = df_top[df_top['Likes Count'] > df_top['Likes Count'].quantile(0.9)]\n",
    "tokens = []\n",
    "for doc in tokenizer.pipe(df_top['Tweet'], batch_size=500):\n",
    "    doc_tokens = []\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in stop_words) & (token.is_punct is False) & (token.is_space is False):\n",
    "            doc_tokens.append(token.lemma_.lower())\n",
    "    tokens.append(doc_tokens)\n",
    "    \n",
    "df_top['like_tokens'] = tokens\n",
    "\n",
    "top_count = Counter()\n",
    "for doc in tokens:\n",
    "    top_count.update(doc)\n",
    "top_count.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "subj = lambda x: TextBlob(x).subjectivity\n",
    "senta = lambda x: TextBlob(x).polarity\n",
    "\n",
    "df['Subjectivity'] = df['Tweet'].apply(subj)\n",
    "df['Sentiment'] = df['Tweet'].apply(senta)\n",
    "\n",
    "df_trump['Subjectivity'] = df_trump['Tweet'].apply(subj)\n",
    "df_trump['Sentiment'] = df_trump['Tweet'].apply(senta)\n",
    "\n",
    "df_biden['Subjectivity'] = df_biden['Tweet'].apply(subj)\n",
    "df_biden['Sentiment'] = df_biden['Tweet'].apply(senta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, 0.0835517950935405\n",
      "Trump, 0.09077470197483492\n",
      "Biden, 0.10920995477507763\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall,\", df['Sentiment'].mean())\n",
    "print(\"Trump,\", df_trump['Sentiment'].mean())\n",
    "print(\"Biden, \", df_biden['Sentiment'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall 0.3652150355861506\n",
      "Trump 0.38315128055326403\n",
      "Biden 0.39690158037524315\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall\", df['Subjectivity'].mean())\n",
    "print(\"Trump\", df_trump['Subjectivity'].mean())\n",
    "print(\"Biden\", df_biden['Subjectivity'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          (0.1259259259259259, 0.2851851851851852)\n",
       "1                                        (0.0, 0.0)\n",
       "2        (0.26666666666666666, 0.39999999999999997)\n",
       "3                                        (0.5, 0.5)\n",
       "4                         (0.4666666666666666, 0.5)\n",
       "                           ...                     \n",
       "5045     (0.26666666666666666, 0.18888888888888888)\n",
       "5046                                     (0.0, 0.0)\n",
       "5047     (0.11212121212121212, 0.30833333333333335)\n",
       "5048    (-0.03750000000000001, 0.46249999999999997)\n",
       "5049    (-0.09722222222222221, 0.10555555555555556)\n",
       "Name: Tweet, Length: 5050, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now think do you want to scatter just the mean or do you want to try and scatter all the scores?\n",
    "df['Tweet'].apply(lambda x: TextBlob(x).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.083552</td>\n",
       "      <td>0.365215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>0.090775</td>\n",
       "      <td>0.383151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biden</th>\n",
       "      <td>0.109210</td>\n",
       "      <td>0.396902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment  Subjectivity\n",
       "Overall   0.083552      0.365215\n",
       "Trump     0.090775      0.383151\n",
       "Biden     0.109210      0.396902"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scatter = pd.DataFrame(data=[[0.0835517950935405, 0.3652150355861506], [0.09077470197483492, 0.38315128055326403], [0.10920995477507763, 0.39690158037524315]],\n",
    "                         index=[\"Overall\", \"Trump\", \"Biden\"], columns=['Sentiment', 'Subjectivity'])\n",
    "df_scatter#.plot.scatter(x=df_scatter.Sentiment, y=df_scatter.Subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to use in Tableau\n",
    "# df_trump['Tweet'].to_csv('../data/dftrump.csv')\n",
    "# df_biden['Tweet'].to_csv('../data/dfbiden.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the bag of words method or TF-IDF for topic modeling. I will just use BoW for this exercise\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_extra = ('trump', \"trump's\", \"trump.\", \"trump\\'s\", 'joe', 'biden', 'donald', '2020:')\n",
    "\n",
    "trump_docs = []\n",
    "for tokens in df_trump['trump_tokens']:\n",
    "    trump_list = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words_extra:\n",
    "            trump_list.append(token)\n",
    "    trump_docs.append(trump_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_words = gensim.corpora.Dictionary(trump_docs)\n",
    "trump_corpus = [trump_words.doc2bow(doc) for doc in trump_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "                corpus=trump_corpus,\n",
    "                id2word=trump_words,\n",
    "                num_topics=10,\n",
    "                random_state=42,\n",
    "                update_every=1,\n",
    "                passes=10,\n",
    "                alpha='auto',\n",
    "                per_word_topics=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.007*\"win\" + 0.006*\"lose\" + 0.005*\"think\" + 0.005*\"vote\" + 0.005*\"go\" + 0.004*\"know\" + 0.003*\"say\" + 0.003*\"want\" + 0.003*\"uk\" + 0.003*\"hope\"')\n",
      "(1, '0.009*\"trump:\" + 0.006*\"vote\" + 0.005*\"win\" + 0.004*\"chance\" + 0.004*\"attack\" + 0.004*\"2020\" + 0.003*\"day\" + 0.003*\"college\" + 0.003*\"electoral\" + 0.003*\"russian\"')\n",
      "(2, '0.006*\"president\" + 0.005*\"campaign\" + 0.004*\"announce\" + 0.004*\"state\" + 0.004*\"@realdonaldtrump\" + 0.003*\"week\" + 0.003*\"vote\" + 0.003*\"foreign\" + 0.003*\"hold\" + 0.003*\"talk\"')\n",
      "(3, '0.010*\"vote\" + 0.007*\"debate\" + 0.007*\"presidential\" + 0.005*\"president\" + 0.005*\"campaign\" + 0.005*\"win\" + 0.005*\"day\" + 0.005*\"@realdonaldtrump\" + 0.003*\"ðŸ‡ºðŸ‡¸\" + 0.003*\"#trump\"')\n",
      "(4, '0.007*\"poll\" + 0.005*\"say\" + 0.004*\"debate\" + 0.004*\"watch\" + 0.003*\"follow\" + 0.003*\"president\" + 0.003*\"day\" + 0.003*\"white\" + 0.003*\"lead\" + 0.003*\"people\"')\n",
      "(5, '0.006*\"say\" + 0.005*\"president\" + 0.005*\"win\" + 0.005*\"american\" + 0.004*\"poll\" + 0.004*\"@realdonaldtrump\" + 0.004*\"supreme\" + 0.004*\"2\" + 0.003*\"day\" + 0.003*\"republican\"')\n",
      "(6, '0.015*\"vote\" + 0.009*\"president\" + 0.006*\"peaceful\" + 0.006*\"say\" + 0.005*\"power\" + 0.005*\"win\" + 0.005*\"transfer\" + 0.004*\"claim\" + 0.004*\"debate\" + 0.004*\"commit\"')\n",
      "(7, '0.013*\"win\" + 0.006*\"say\" + 0.006*\"president\" + 0.004*\"campaign\" + 0.004*\"voter\" + 0.004*\"result\" + 0.004*\"itâ€™s\" + 0.004*\"trumpâ€™s\" + 0.004*\"brexit\" + 0.003*\"wait\"')\n",
      "(8, '0.010*\"president\" + 0.010*\"win\" + 0.006*\"test\" + 0.006*\"debate\" + 0.005*\"positive\" + 0.004*\"want\" + 0.004*\"say\" + 0.004*\"brexit\" + 0.004*\"covid-19\" + 0.004*\"tell\"')\n",
      "(9, '0.008*\"despite\" + 0.008*\"covid\" + 0.007*\"beating\" + 0.007*\"poll:\" + 0.007*\"hospitalise\" + 0.006*\"president\" + 0.005*\"win\" + 0.004*\"exclusive\" + 0.004*\"white\" + 0.004*\"year\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in lda_model.show_topics():\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.049*\"american\" + 0.048*\"incumbent\" + 0.047*\"dakota\" + 0.047*\"announce\" + 0.047*\"&lt;-\" + 0.046*\"south\" + 0.046*\"in:\" + 0.046*\"normalize\" + 0.045*\"relation\" + 0.045*\"peace\"')\n",
      "(1, '0.047*\"dakota\" + 0.047*\"normalize\" + 0.046*\"relevance.\" + 0.046*\"achievement\" + 0.046*\"incumbent\" + 0.046*\"relation\" + 0.046*\"in:\" + 0.046*\"agree\" + 0.046*\"american\" + 0.045*\"@jim_jordan\"')\n",
      "(2, '0.047*\"@jim_jordan\" + 0.046*\"in:\" + 0.046*\"north\" + 0.046*\"foreign\" + 0.046*\"here.\" + 0.046*\"announce\" + 0.046*\"dying.\" + 0.046*\"week\" + 0.046*\"achievement\" + 0.046*\"&lt;-\"')\n",
      "(3, '0.051*\"agree\" + 0.049*\"broke\" + 0.048*\"peace\" + 0.048*\"dakota\" + 0.048*\"dying.\" + 0.047*\"relation\" + 0.046*\"normalize\" + 0.046*\"announce\" + 0.046*\"week\" + 0.046*\"american\"')\n",
      "(4, '0.046*\"relevance.\" + 0.046*\"dying.\" + 0.046*\"achievement\" + 0.046*\"normalize\" + 0.046*\"incumbent\" + 0.046*\"in:\" + 0.046*\"agree\" + 0.046*\"@jim_jordan\" + 0.046*\"foreign\" + 0.046*\"broke\"')\n",
      "(5, '0.047*\"relevance.\" + 0.046*\"north\" + 0.046*\"week\" + 0.046*\"agree\" + 0.046*\"american\" + 0.046*\"relation\" + 0.046*\"south\" + 0.046*\"peace\" + 0.046*\"policy\" + 0.046*\"president\"')\n",
      "(6, '0.050*\"achievement\" + 0.049*\"south\" + 0.048*\"dakota\" + 0.048*\"week\" + 0.048*\"announce\" + 0.047*\"north\" + 0.047*\"relevance.\" + 0.046*\"peace\" + 0.046*\"normalize\" + 0.046*\"in:\"')\n",
      "(7, '0.050*\"broke\" + 0.049*\"north\" + 0.049*\"&lt;-\" + 0.048*\"dying.\" + 0.048*\"week\" + 0.048*\"agree\" + 0.047*\"president\" + 0.046*\"in:\" + 0.046*\"achievement\" + 0.046*\"relation\"')\n",
      "(8, '0.045*\"here.\" + 0.045*\"peace\" + 0.045*\"&lt;-\" + 0.045*\"foreign\" + 0.045*\"policy\" + 0.045*\"broke\" + 0.045*\"president\" + 0.045*\"dakota\" + 0.045*\"south\" + 0.045*\"american\"')\n",
      "(9, '0.048*\"here.\" + 0.047*\"&lt;-\" + 0.046*\"president\" + 0.046*\"foreign\" + 0.046*\"week\" + 0.046*\"american\" + 0.046*\"policy\" + 0.046*\"announce\" + 0.046*\"relation\" + 0.046*\"incumbent\"')\n"
     ]
    }
   ],
   "source": [
    "biden_docs = []\n",
    "for tokens in df_biden['biden_tokens']:\n",
    "    biden_list = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words_extra:\n",
    "            biden_list.append(token)\n",
    "    biden_docs.append(trump_list)\n",
    "    \n",
    "biden_words = gensim.corpora.Dictionary(biden_docs)\n",
    "biden_corpus = [biden_words.doc2bow(doc) for doc in biden_docs]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "                corpus=biden_corpus,\n",
    "                id2word=biden_words,\n",
    "                num_topics=10,\n",
    "                random_state=42,\n",
    "                update_every=1,\n",
    "                passes=10,\n",
    "                alpha='auto',\n",
    "                per_word_topics=True\n",
    "                )\n",
    "for topic in lda_model.show_topics():\n",
    "    print(topic)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "US-Election-Tweets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "NLP-4-1 (Python 3)",
   "language": "python",
   "name": "nlp-4-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
